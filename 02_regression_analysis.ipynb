{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd8a7e4-9872-4287-a2cb-9cd9a61f5d2b",
   "metadata": {},
   "source": [
    "# Notebook 2: Conducting and Evaluating Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faf29686-bf9d-4a2a-9ba3-001e38aca3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829a146-3845-4f11-9f44-fa8531157f76",
   "metadata": {},
   "source": [
    "Import datasets that were preprocessed in Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4353733e-1ac8-48a4-8f19-d9a06e3e9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_data = pd.read_csv(\"data/wb_data.csv\")\n",
    "wb_data_short = pd.read_csv(\"data/wb_data_short.csv\")\n",
    "whr_data = pd.read_csv(\"data/whr_data.csv\")\n",
    "\n",
    "wb_data.index = wb_data[\"Country Name\"]\n",
    "wb_data.drop(columns=[\"Country Name\", \"Country Name.1\"], inplace=True)\n",
    "wb_data_short.index = wb_data_short[\"Country Name\"]\n",
    "wb_data_short.drop(columns=[\"Country Name\", \"Country Name.1\"], inplace=True)\n",
    "\n",
    "\n",
    "whr_data.index = whr_data[\"Country name\"]\n",
    "whr_data.drop(columns=[\"Country name\", \"Country name.1\"], inplace=True)\n",
    "#whr_data.head(20)\n",
    "\n",
    "# sort by index\n",
    "wb_data.sort_index(inplace=True)\n",
    "wb_data_short.sort_index(inplace=True)\n",
    "whr_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77c7d075-37bd-4029-b78c-e919cb3edcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# test: are the datasets equal\n",
    "print(sorted(list(wb_data.index))==sorted(list(whr_data.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599711a-b013-4b08-8954-0739460b0b7a",
   "metadata": {},
   "source": [
    "## Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b10df82-1d64-4ad5-8ab9-db85d098ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop everything but life satisfaction ladder score from whr data\n",
    "whr_scores = whr_data[\"Ladder score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0646489-3331-4051-962b-cf301febe530",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "def split_data(data, gt, test_size):\n",
    "    \"\"\"\n",
    "    split dataset into train and test set\n",
    "    \n",
    "    returns: tuple of numpy arrays (train_set, test_set)\n",
    "    \"\"\"\n",
    "    test_set = data.sample(n=test_size)\n",
    "    test_country_names = list(test_set.index.values)\n",
    "    train_set = data.drop(labels=test_country_names)\n",
    "    \n",
    "    test_gt = gt.loc[test_set.index.values]\n",
    "    train_gt = gt.drop(labels=test_country_names)\n",
    "    \n",
    "    return train_set, test_set, train_gt, test_gt\n",
    "\n",
    "train, test, train_gt, test_gt = split_data(wb_data_short, whr_scores, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "013c5d94-90db-458e-bd68-b46ff01b3b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 120) (30, 120) (120,) (30,)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, train_gt.shape, test_gt.shape)\n",
    "print(list(test.index)==list(test_gt.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9d66-517a-4e8b-8776-5b3e5d2f7749",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc99b529-429e-4e4b-bcbb-c55ef5e0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def n_fold_ceval(n, data, gt, test_size, loss):\n",
    "    \"\"\"\n",
    "    perform n-fold validation\n",
    "    \n",
    "    args: number of validations (n), dataset of indicators (data), groundtruth data (gt), size of test set (test size), loss function (loss)\n",
    "    returns: list of length n, each entry contains loss for one validation loop\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    for i in range(0,n):\n",
    "        train, test, train_gt, test_gt = split_data(data, gt, test_size)\n",
    "        \n",
    "        reg = LinearRegression().fit(train, train_gt)\n",
    "        test_pred = reg.predict(test)\n",
    "        loss = sklearn.metrics.mean_squared_error(test_gt, test_pred)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18734c9f-c118-4ede-85f5-2f2206e4b256",
   "metadata": {},
   "source": [
    "Let's see how linear regression performs on wb_data and wb_data_short (redundant indicators removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8416c5d9-01e2-42df-bd81-2839deb807a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.945441120476232\n",
      "[  6.51939572   6.26261574   7.58159913   1.63483737   5.97839956\n",
      "   4.87304204   2.66028739   7.90599941   7.39089931  34.86942516\n",
      "   2.26733357   3.66616242  10.3733022    2.6190404    6.72689131\n",
      " 288.54859496   9.37142456   3.43677257  25.49719684   2.14758935\n",
      "   7.67526786  44.05844199   9.77266899  29.71788408  13.15540793\n",
      "   6.7018282    6.4644629   13.77506163   3.00843642   4.48618897\n",
      "   4.94498779   2.26956486  40.50720183  62.64376693   3.68594704\n",
      "  12.99721999  13.45737186   9.21572372  11.1891592    9.03848938\n",
      "  57.69502699   8.30333794  82.60712957   2.82862587  20.08378955\n",
      "  10.52933585   4.70173479   1.62237674   2.69534614   9.85536205]\n"
     ]
    }
   ],
   "source": [
    "losses = np.array(n_fold_ceval(1500, wb_data, whr_scores, 30))\n",
    "losses_mean = losses.mean()\n",
    "\n",
    "print(losses_mean)\n",
    "print(losses[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e2d41-a2d9-4acd-81ac-faeba1db3ba3",
   "metadata": {},
   "source": [
    "For high n, the mse-loss is around 5. We print the first 50 entries of the loss array to check for outliers. It turns out that the variance is quite large and the loss is roughly in a range of [1, 25]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
