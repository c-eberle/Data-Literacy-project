{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd8a7e4-9872-4287-a2cb-9cd9a61f5d2b",
   "metadata": {},
   "source": [
    "# Notebook 2: Conducting and Evaluating Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faf29686-bf9d-4a2a-9ba3-001e38aca3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829a146-3845-4f11-9f44-fa8531157f76",
   "metadata": {},
   "source": [
    "Import datasets that were preprocessed in Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4353733e-1ac8-48a4-8f19-d9a06e3e9312",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_data = pd.read_csv(\"data/wb_data.csv\")\n",
    "wb_data_short = pd.read_csv(\"data/wb_data_short.csv\")\n",
    "whr_data = pd.read_csv(\"data/whr_data.csv\")\n",
    "\n",
    "wb_data.index = wb_data[\"Country Name\"]\n",
    "wb_data.drop(columns=[\"Country Name\", \"Country Name.1\"], inplace=True)\n",
    "wb_data_short.index = wb_data_short[\"Country Name\"]\n",
    "wb_data_short.drop(columns=[\"Country Name\", \"Country Name.1\"], inplace=True)\n",
    "\n",
    "\n",
    "whr_data.index = whr_data[\"Country name\"]\n",
    "whr_data.drop(columns=[\"Country name\", \"Country name.1\"], inplace=True)\n",
    "#whr_data.head(20)\n",
    "\n",
    "# sort by index\n",
    "wb_data.sort_index(inplace=True)\n",
    "wb_data_short.sort_index(inplace=True)\n",
    "whr_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77c7d075-37bd-4029-b78c-e919cb3edcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# test: are the datasets equal\n",
    "print(sorted(list(wb_data.index))==sorted(list(whr_data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746f33e-63b3-4034-a9ba-333fbb65f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop everything but life satisfaction ladder score from whr data\n",
    "whr_scores = whr_data[\"Ladder score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c8d90-44ef-4cc7-a217-d9f4c5d3922e",
   "metadata": {},
   "source": [
    "## Pearson correlation coefficients\n",
    "Aim: Get the correlation coefficient of each indicator with the whr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e999b304-b4fe-44fc-8e47-cfa2ecf0b1c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f273fc24670b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mindicator_corr_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicator_corr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindicator_corr\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "indicator_corr = wb_data_short.corr(method=\"pearson\")\n",
    "indicator_corr\n",
    "indicator_corr[indicator_corr>0.8]\n",
    "\n",
    "indicator_corr_list = []\n",
    "\n",
    "#print(sorted(indicator_corr[indicator_corr>0.8].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599711a-b013-4b08-8954-0739460b0b7a",
   "metadata": {},
   "source": [
    "## Split data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0646489-3331-4051-962b-cf301febe530",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "def split_data(data, gt, test_size):\n",
    "    \"\"\"\n",
    "    split dataset into train and test set\n",
    "    \n",
    "    returns: tuple of numpy arrays (train_set, test_set)\n",
    "    \"\"\"\n",
    "    test_set = data.sample(n=test_size)\n",
    "    test_country_names = list(test_set.index.values)\n",
    "    train_set = data.drop(labels=test_country_names)\n",
    "    \n",
    "    test_gt = gt.loc[test_set.index.values]\n",
    "    train_gt = gt.drop(labels=test_country_names)\n",
    "    \n",
    "    return train_set, test_set, train_gt, test_gt\n",
    "\n",
    "train, test, train_gt, test_gt = split_data(wb_data_short, whr_scores, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c5d94-90db-458e-bd68-b46ff01b3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape, train_gt.shape, test_gt.shape)\n",
    "print(list(test.index)==list(test_gt.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659f9d66-517a-4e8b-8776-5b3e5d2f7749",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99b529-429e-4e4b-bcbb-c55ef5e0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def n_fold_ceval(n, data, gt, test_size, loss):\n",
    "    \"\"\"\n",
    "    perform n-fold validation\n",
    "    \n",
    "    args: number of validations (n), dataset of indicators (data), groundtruth data (gt), size of test set (test size), loss function (loss)\n",
    "    returns: list of length n, each entry contains loss for one validation loop\n",
    "    \"\"\"\n",
    "    loss_list = []\n",
    "    for i in range(0,n):\n",
    "        train, test, train_gt, test_gt = split_data(data, gt, test_size)\n",
    "        \n",
    "        reg = LinearRegression().fit(train, train_gt)\n",
    "        test_pred = reg.predict(test)\n",
    "        loss = sklearn.metrics.mean_squared_error(test_gt, test_pred)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18734c9f-c118-4ede-85f5-2f2206e4b256",
   "metadata": {},
   "source": [
    "Let's see how linear regression performs on wb_data and wb_data_short (redundant indicators removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416c5d9-01e2-42df-bd81-2839deb807a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.array(n_fold_ceval(1500, wb_data, whr_scores, 30))\n",
    "losses_mean = losses.mean()\n",
    "\n",
    "print(losses_mean)\n",
    "print(losses[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e2d41-a2d9-4acd-81ac-faeba1db3ba3",
   "metadata": {},
   "source": [
    "For high n, the mse-loss is around 5. We print the first 50 entries of the loss array to check for outliers. It turns out that the variance is quite large and the loss is roughly in a range of [1, 25]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
